{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40aabf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae40dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Logs/\"\n",
    "save_path = \"./Saved/\"\n",
    "\n",
    "from load_logs import *\n",
    "from evaluation import *\n",
    "from features import *\n",
    "from visualize import *\n",
    "\n",
    "logs, log_labels = read_logs_and_labels(\"./Saved/logs.txt\", \"./Saved/labels.txt\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import random\n",
    "import hdbscan\n",
    "import itertools\n",
    "\n",
    "from bregclus.models import BregmanHard\n",
    "from bregclus.divergences import euclidean\n",
    "from multiprocessing import get_context\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from scipy import sparse\n",
    "from multiprocessing import Pool\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076e88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to define necessary functions\n",
    "#Since this is based on a knn idea we will need to calculate euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46429d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest neighbour - gets x number of nearest nodes\n",
    "def nearest(x, y_row, neighbors, labels): #specify number of neighbours to return\n",
    "    distances = np.linalg.norm(x - y_row, axis=1)#numpy array of distances\n",
    "    size, y = np.shape(x)\n",
    "    itera = np.arange(0,size).reshape(-1,1)\n",
    "    for i in range(len(labels)):\n",
    "        distances = np.c_[distances,labels[i]]\n",
    "    distances = np.c_[distances,itera]\n",
    "    distances = distances[np.argsort(distances[:, 0])]\n",
    "    neighborsList, neighborsLabels, iteraList = list(), list(), list()\n",
    "    for i in range(neighbors): #27093\n",
    "        neighborsList.append(distances[i][0])\n",
    "        neighborsLabels.append(distances[i][1:len(distances[i])-1])\n",
    "        iteraList.append(distances[i][len(distances[i])-1])\n",
    "    return neighborsList,neighborsLabels,iteraList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e78306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUp(labels, lookup, which):\n",
    "    arr = np.array(labels)\n",
    "    x,y = np.shape(arr)\n",
    "    indices = np.argwhere(arr[which] == lookup)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6811084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstTrue(boolArr):\n",
    "    for i in range(len(boolArr)):\n",
    "        if boolArr[i] == True:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540d12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recluster(x,y,silVal, itera): #Recluster based on silhouette coefficient (i.e whichever node here has a higher coefficient)\n",
    "    print(itera)\n",
    "    if silVal[int(itera[0])] > silVal[int(itera[1])]:\n",
    "        return x\n",
    "    else:\n",
    "        return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506e8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27326be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEqual(x,y):\n",
    "    if x == y:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3900459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current and nearest are same cluster then true otherwise false\n",
    "def checkClus(x,y):\n",
    "    boolArr = list(map(isEqual, x, y))\n",
    "    return boolArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280350ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(x,y,labels,silVal,itera,silVal1): #form boolean array from checkClus, if majority are true then the node should be in the cluster, otherwise not\n",
    "    boolArr=checkClus(x,y)\n",
    "    trueCount, total,first = sum(boolArr), len(boolArr), firstTrue(boolArr)\n",
    "    if (trueCount)/(total) > 0.5:\n",
    "        #pass vote of node being in cluster\n",
    "        if (boolArr[0] == False): #when consensus is passed but what our clustering is based on does not agree\n",
    "            print(\"did not fully pass\")\n",
    "            ind1 = lookUp(labels,x[first],first)#need to sort this out such that we determine if the nearest nodes value is better\n",
    "            ind2 = lookUp(labels,x[0],0)#or if the current nodes value is better\n",
    "            ind3 = lookUp(labels,y[0],0)\n",
    "            firstValList = np.intersect1d(ind1, ind2, assume_unique=False, return_indices=False)\n",
    "            x1 = np.shape(firstValList)\n",
    "            secondValList = np.intersect1d(ind1, ind3, assume_unique=False, return_indices=False)\n",
    "            x2 = np.shape(secondValList)\n",
    "            if x1 > x2: #determine which node classification is agreed on more\n",
    "                print(\"replacing \"+ str(x[0]) +\" with \"+ str(x[0]) + \" at \"+str(itera))\n",
    "                return True, x[0]\n",
    "            else:\n",
    "                print(\"replacing \"+ str(x[0]) +\" with \"+ str(y[0])+ \" at \"+str(itera))\n",
    "                return True, y[0]\n",
    "            #return True, recluster(x[0],y[0],silVal1,itera)\n",
    "        return True, x[0]\n",
    "    else:\n",
    "        print(\"failed!\")\n",
    "        \n",
    "        #pass the false vote - node is not in cluster\n",
    "        return False, recluster(x[0],y[0],silVal1,itera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5fff590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehension(X,labels,x,itera,silVal):\n",
    "    silValed = silVal\n",
    "    lb = list()\n",
    "    lb.append(labels[0][itera])\n",
    "    lb.append(labels[1][itera])\n",
    "    lb.append(labels[2][itera])\n",
    "    labelsed = (np.reshape(np.array(labels),(-1,3))).tolist()\n",
    "    labs = labels\n",
    "    it = list()\n",
    "    if itera > 0:\n",
    "        X = np.delete(X,[0,itera-1], axis = 0)\n",
    "        labels = np.delete(labels,[0,itera-1], axis = 1)\n",
    "        silValed = np.delete(silVal,[0,itera-1], axis = 0)\n",
    "    near, tempLab,inds = nearest(X, x, 2, labels)\n",
    "    it.append(itera)\n",
    "    it.append(inds[1])\n",
    "    boolArr1,res1 = consensus(lb,tempLab[1],labs,silValed,it,silVal)\n",
    "    if boolArr1 == True:\n",
    "        return int(res1) #need to sort this out such that we assign a valid cluster number\n",
    "    else: #recluster somehow\n",
    "        print(\"Failed - reclustering\")\n",
    "        return int(res1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce79bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeConsensus(X, labels,silVal):\n",
    "    x,y = np.shape(X)\n",
    "    i = list(range(0,x))\n",
    "    tasks = [*zip(itertools.repeat(X,x),itertools.repeat(labels,x), X,i,itertools.repeat(silVal,x))]\n",
    "    print(\"running consensus\")\n",
    "    #p = Pool(6)#Multiprocessing to speed up run time\n",
    "    with Pool() as p:\n",
    "    #conList = [comprehension(X, labels, x) for x in X]\n",
    "        conList = p.starmap(comprehension, tasks)\n",
    "    #conList = starmap(comprehension, tasks)\n",
    "    #for i in range(len(X)):\n",
    "        #boolArr = list()\n",
    "        #near, tempLab = nearest(X_, X[i], 3, labels) #do not repeat values in proximity\n",
    "        #X_ = np.delete(X, i, axis = 0) #This will exclude the current node from our next nearest calculations\n",
    "        #boolArr1 = checkClus(tempLab[0],tempLab[1])\n",
    "       # boolArr2 = checkClus(tempLab[0],tempLab[2])\n",
    "        #if consensus(boolArr1):\n",
    "          #  conList.append(tempLab[0][0]) #need to sort this out such that we assign a valid cluster number\n",
    "        #elif consensus(boolArr2): #here we check its second nearest neighbor before reclustering\n",
    "         #   conList.append(tempLab[1][0])\n",
    "       # else: #recluster somehow\n",
    "           # conList.append(tempLab[0][0])\n",
    "        #print(conList)\n",
    "    return conList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6d1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd6fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = log_labels\n",
    "            \n",
    "X = get_features(logs, 2, 70)\n",
    "X = X.toarray()\n",
    "\n",
    "idxs = np.where(np.all(X == 0, axis=1))\n",
    "\n",
    "X = np.delete(X, idxs, axis=0)\n",
    "labels_ = np.delete(labels_, idxs)\n",
    "## K Means Labels\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=10,random_state=0).fit(X)\n",
    "kLabels = kmeans.labels_\n",
    "\n",
    "## DBSCAN Labels\n",
    "DBmodel = DBSCAN(eps=0.4,min_samples=200,algorithm=\"auto\",metric=\"cosine\")\n",
    "DBmodel.fit(X)\n",
    "dbLabels = DBmodel.labels_\n",
    "\n",
    "## Birch Label\n",
    "birchmodel = Birch(n_clusters=10, branching_factor=100, threshold=0.5, compute_labels=True)\n",
    "Y = birchmodel.fit_transform(X)\n",
    "birchLabels = birchmodel.labels_\n",
    "\n",
    "#HDBScan Labels\n",
    "model = hdbscan.HDBSCAN(min_cluster_size=500,min_samples=100,cluster_selection_epsilon=0.5,\n",
    "                                        metric=\"euclidean\",algorithm='best')\n",
    "model.fit(X)\n",
    "hdbLabels = model.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79798318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bregman Labels\n",
    "bhc = BregmanHard(n_clusters=10, divergence=euclidean)\n",
    "bhc.fit(X)\n",
    "bLabels = bhc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b9a1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "silVal = silhouette_samples(X, kLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "734830bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "labels = list()\n",
    "labels.append(kLabels)\n",
    "labels.append(hdbLabels)\n",
    "labels.append(bLabels)\n",
    "\n",
    "#x,y,z = nearest(X, X[0], 2, labels)\n",
    "#print(x)\n",
    "#print(y)\n",
    "#print(z)\n",
    "#boolArr = checkClus(y[0],y[1])\n",
    "#print(boolArr)\n",
    "\n",
    "#print(consensus(y[0],y[1],labels,silVal))\n",
    "#x,y = np.shape(X)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8b83ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 27093)\n",
      "(27093, 1832)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(labels))\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e70df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a9369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfeb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "itertools.repeat(silVal, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03234658",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(silVal))\n",
    "print(np.shape(X))\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fac99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recluster(labels[0][26903],labels[0][6036],silVal, [26903,6036]))\n",
    "print(silVal[26903])\n",
    "print(silVal[6036])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import worker\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x,y = np.shape(X)\n",
    "    i = list(range(0,x))\n",
    "    tasks = [*zip(itertools.repeat(X, x),itertools.repeat(labels, x), X, i, itertools.repeat(silVal, x))]\n",
    "    p = Pool(4)\n",
    "    cLabels = p.starmap(worker.comprehension, tasks)\n",
    "    print(cLabels)\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2732f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kLabels[11765])\n",
    "print(cLabels[11765])\n",
    "print(kLabels - cLabels)\n",
    "print(np.shape(np.nonzero(kLabels - cLabels)))\n",
    "#12 nodes changed with db, hdb (in order) - hdb is a better option\n",
    "#11 nodes changed with hdb, birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a1e70d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(cLabels) - set(kLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218aed87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((np.reshape(np.array(labels),(-1,3))).tolist())\n",
    "x = list()\n",
    "x.append(labels[0][3144])\n",
    "x.append(labels[1][3144])\n",
    "x.append(labels[2][3144])\n",
    "y = list()\n",
    "y.append(labels[0][11981])\n",
    "y.append(labels[1][11981])\n",
    "y.append(labels[2][11981])\n",
    "recluster(labels[0][3144],labels[0][11981],silVal, [3144, 11981.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c97c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comprehension(X,labels,X[3144],3144,silVal)) #did not fully pass\n",
    "#[3590.0, 1393.0]\n",
    "#Succesful recluster\n",
    "#did not fully pass\n",
    "#[1002.0, 19211.0]\n",
    "#Succesful recluster\n",
    "#failed!\n",
    "#[4676.0, 11270.0]\n",
    "#Succesful recluster\n",
    "#Failed - reclustering\n",
    "#did not fully pass\n",
    "#[3144.0, 1403.0]\n",
    "#Succesful recluster\n",
    "#did not fully pass\n",
    "#[8627.0, 24408.0]\n",
    "\n",
    "#fixed issue where passing wrong label list\n",
    "print(str(labels[0][4676]) + \" labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3895de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(\"Consensus Bigram Clustering using UMAP\", X, cLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b03270",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_clustering('Consensus Bigram Clustering', X, labels_, cLabels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = log_labels\n",
    "            \n",
    "X = get_features(logs, 3, 90)\n",
    "X = X.toarray()\n",
    "\n",
    "idxs = np.where(np.all(X == 0, axis=1))\n",
    "\n",
    "X = np.delete(X, idxs, axis=0)\n",
    "labels_ = np.delete(labels_, idxs)\n",
    "## K Means Labels\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=10,random_state=0).fit(X)\n",
    "kLabels = kmeans.labels_\n",
    "\n",
    "## DBSCAN Labels\n",
    "DBmodel = DBSCAN(eps=0.4,min_samples=200,algorithm=\"auto\",metric=\"cosine\")\n",
    "DBmodel.fit(X)\n",
    "dbLabels = DBmodel.labels_\n",
    "\n",
    "## Birch Label\n",
    "birchmodel = Birch(n_clusters=10, branching_factor=100, threshold=0.5, compute_labels=True)\n",
    "Y = birchmodel.fit_transform(X)\n",
    "birchLabels = birchmodel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "labels.append(kLabels)\n",
    "labels.append(dbLabels)\n",
    "labels.append(birchLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33835770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import worker\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x,y = np.shape(X)\n",
    "    i = list(range(0,x))\n",
    "    tasks = [*zip(itertools.repeat(X, x),itertools.repeat(labels, x), X, i, itertools.repeat(silVal, x))]\n",
    "    p = Pool(4)\n",
    "    cLabels = p.starmap(worker.comprehension, tasks)\n",
    "    print(cLabels)\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(\"Consensus Trigram Clustering using UMAP\", X, cLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a283609",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_clustering('Consensus Bigram Clustering', X, labels_, cLabels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c3c993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928689f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bf439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
