{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.8.27)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hdbscan) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hdbscan) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hdbscan) (1.7.0)\n",
      "Requirement already satisfied: cython>=0.27 in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hdbscan) (0.29.24)\n",
      "Requirement already satisfied: six in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hdbscan) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hdbscan) (1.21.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\riley\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn>=0.20->hdbscan) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_logs import *\n",
    "from evaluation import *\n",
    "from features import *\n",
    "from visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, log_labels = read_logs_and_labels(\"./Saved/logs.txt\", \"./Saved/labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import hdbscan\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"] \n",
    "# leaf_size = [10, 20, 30, 40, 50] \n",
    "eps = [0.4, 0.5, 0.6, 0.7, 0.8] #cluster_selection_epsilon parameter for hdbscan\n",
    "metrics = [\"precomputed\", \"euclidean\",\"manhattan\"]\n",
    "min_samples =  [100, 200, 300, 400, 500] #is it worth it to use the min_sample from DBSCAN and cache using memory?\n",
    "min_cluster_size = [100, 200, 300, 400, 500]\n",
    "#cluster_selection_methods=[\"eom\", \"leaf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(logs, gram, min_df):\n",
    "    \n",
    "    labels_ = log_labels\n",
    "            \n",
    "    X = get_features(logs, gram, min_df)\n",
    "    X = X.toarray()\n",
    "\n",
    "    idxs = np.where(np.all(X == 0, axis=1))\n",
    "\n",
    "    X = np.delete(X, idxs, axis=0)\n",
    "    labels_ = np.delete(labels_, idxs)\n",
    "\n",
    "    result_header = [\"Eps\", \"Min Cluster Size\", \"Min Sample Size\", \"Metric\", \"VMeasure\", \"Fowlkes-Mallows\", \"Labels\"]\n",
    "    results = []\n",
    "    \n",
    "    Y = pairwise_distances(X, metric=\"cosine\")\n",
    "    \n",
    "    #using min sample = 100 based off of dbscan results\n",
    "    \n",
    "    for metric in metrics:\n",
    "        for min_cl in min_cluster_size:\n",
    "            for min_s in min_samples:\n",
    "                for ep in eps:\n",
    "                        model = hdbscan.HDBSCAN(min_cluster_size=min_cl,min_samples=min_s,cluster_selection_epsilon=0.5,\n",
    "                                                metric=metric,algorithm='best')\n",
    "\n",
    "                        if metric == \"precomputed\":\n",
    "                            model.fit(Y)\n",
    "                        else :\n",
    "                            model.fit(X)\n",
    "\n",
    "                        labels = model.labels_\n",
    "\n",
    "                        vm = evaluate_vmeasure(labels_, labels)\n",
    "                        fm = evaluate_fm(labels_, labels)\n",
    "\n",
    "                        lst1 = set(labels)\n",
    "\n",
    "                        result = [0.5, min_cl, min_s, metric, vm, fm, len(lst1)-1]\n",
    "                        results.append(result)\n",
    "\n",
    "                        tab_results(result_header, results) \n",
    "\n",
    "                \n",
    "    tab_results(result_header, results)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search(logs, 2, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(logs, 3, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Feature Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = log_labels\n",
    "\n",
    "X = get_features(logs, 2, 70)\n",
    "X = X.toarray()\n",
    "\n",
    "idxs = np.where(np.all(X == 0, axis=1))\n",
    "\n",
    "X = np.delete(X, idxs, axis=0)\n",
    "labels_ = np.delete(labels_, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hdbscan.HDBSCAN(min_cluster_size=500,min_samples=100,cluster_selection_epsilon=0.5,\n",
    "                                        metric=\"euclidean\",algorithm='best')\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = set(labels)\n",
    "lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(\"HDBSCAN Bigram Clustering using UMAP\", X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_clustering('HDBSCAN Bigram Clustering', X, labels_, labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Feature Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ = log_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_features(logs, 3, 90)\n",
    "X = X.toarray()\n",
    "\n",
    "idxs = np.where(np.all(X == 0, axis=1))\n",
    "\n",
    "X = np.delete(X, idxs, axis=0)\n",
    "labels_ = np.delete(labels_, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Y = pairwise_distances(X, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hdbscan.HDBSCAN(min_cluster_size=500,min_samples=100,cluster_selection_epsilon=0.5,\n",
    "                                        metric=\"precomputed\",algorithm='best')\n",
    "model.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = set(labels)\n",
    "lst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_clusters(\"HDBSCAN Trigram Clustering using UMAP - Min S 100\", X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_clustering('HDBSCAN Trigram Clustering - Min S 100', X, labels_, labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.single_linkage_tree_.plot(cmap='viridis', colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.condensed_tree_.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
